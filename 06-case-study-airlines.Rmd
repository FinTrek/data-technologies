---
knit: bookdown::preview_chapter
---

# US flights


HH: what I like to include here:

- discussion of airlines: number of passengers, centralized/de-centralization (hubs or not), fuel consumption
- discussion of delays: by time of day, day of week, airport, airline
- finding exceptions: delays of more than 24h, balloons at 600 mph, ...
- making a movie of the flights

I would also like to use new data rather than the Expo data.


There were 445,827 national flights recorded for January 2016:
```{r, message=FALSE, warning=FALSE}
library(ggplot2)
ontime <- read.csv("data/airlines/ontime/On_Time_On_Time_Performance_2016_1.csv")
dim(ontime)
require(dplyr)
tails <- ontime %>% group_by(TailNum) %>% summarize(
  numFlights = n(),
  carrier = UniqueCarrier[1],
  miles = sum(Distance)
)
qplot(reorder(carrier, miles), miles, data=tails, varwidth=TRUE, fill=carrier, geom="boxplot") + ylim(c(0,150000)) 
qplot(miles, data=tails, fill=carrier) + xlim(c(0,150000)) + facet_wrap(~carrier, scales="free_y")
```
Southwest (WN) flies the heck out of its planes, but it is beaten at this game by a lot of the very small airline carriers, at the front of which is Spirit Airlines (NK).
What we cannot see from the boxplots is that some of these airline carriers have several modes for the number of miles that their planes fly. United and American seem to have a couple of planes that fly only very rarely. Carrier AS has two modes: one mode at a very high number of miles, the other at around 75,000 miles.  

All times in the ontime data set are in local time. This is problematic for almost any data analysis. Even ordering flights by their departure time over the course of a day is not possible unless we are only considering flights in the same time zone. 

Because all of the locations we are interested in, are airports, we can make use of the
[National Transportation Atlas Database](http://www.rita.dot.gov/bts/sites/rita.dot.gov.bts/files/publications/national_transportation_atlas_database/2011/index.html) provided by the Bureau of Transportation Statistics. In this database, airports are listed with geographic location in latitude and longitude. 
```{r, message=FALSE}
library(foreign)
airports <- read.dbf("data/airlines/airports/airports.dbf")
# we can reduce our data set to airports only 
table(airports$LAN_FA_TY)

airports <- subset(airports, LAN_FA_TY=="AIRPORT")
qplot(LONGITUDE, LATITUDE, data=airports)
```

There is a slew of different approaches and (semi-free) online services available to resolve issues around time zones. Here, we are using the Google Maps Time Zone API to get time zones for every one of the airports above. In order to run the following example, yu will have to sign up for this service to get an API key. Make yourself familiar with any limitations of the service so you don't accidentally ramp up any charges.

```{r, eval=FALSE}
timestamp <- 1452427200 # epoch time of Jan 10, 2016 12:00 pm

i <- 1
stringi <- sprintf("https://maps.googleapis.com/maps/api/timezone/json?location=%s,%s&timestamp=1452427200&key=PASTE-YOUR-KEY-HERE", airports$LATITUDE[i], airports$LONGITUDE[i])

library(rjson)
json_data <- fromJSON(file=stringi)
```

```{r, echo=FALSE, eval=FALSE}
timestamp <- 1452427200 # epoch time of Jan 10, 2016 12:00 pm
library(rjson)

#airport_tz <- NULL
for (i in 3180:XXX) {
  stringi <- sprintf("https://maps.googleapis.com/maps/api/timezone/json?location=%s,%s&timestamp=1452427200&key=AIzaSyCYXzAUh7Tq9CQ9dHvNFdkZ7QBdrfKNS3U", airports$LATITUDE[i], airports$LONGITUDE[i])
  cat(i)
  cat("\n")
  json <- fromJSON(file=stringi)
  if (json$status =="OK") {
    temp <- data.frame(ID = airports$LOCID[i], json)
    airport_tz <- rbind(airport_tz, temp)
  }
}
write.csv(airport_tz, file="data/airport-timezones.csv", row.names=FALSE)
```

What kind of time shift does each of the time zones imply compared to a reference timezone and date? Using UTC as the reference time zone we calculate the difference in hours of the day on January 24 of 2016. 
```{r}
# reference date
pb.date <- ymd_hm("2016-01-24 12:00", tz="UTC")
hour(pb.date)

airport_tz$timeZoneId <- as.character(airport_tz$timeZoneId)
airport_tz$tz_hours <- 12 - sapply(airport_tz$timeZoneId, function(x) hour(format(pb.date, tz=x, usetz=TRUE)))

airports <- merge(airports, airport_tz[, c("ID", "timeZoneName", "timeZoneId", "tz_hours")], all.x=TRUE, by.x="LOCID", by.y="ID")
```

Using the time zone information we can transform local times at airports into global times referenced to UTC, which we then use to order the ontime data according to the time that flights took place ***needs a more precise definition***.
```{r}
# merge time zone data into ontime data by  origin and destination 
# adjust local departure times by origin and arrival times by destination

```
Order flights to identify ghost flights
```{r}


ontime$Departure <- ymd(as.character(ontime$FlightDate))
hour(ontime$Departure) <- ontime$CRSDepTime %/% 100
minute(ontime$Departure) <- ontime$CRSDepTime %% 100
ontime <- ontime %>% group_by(TailNum) %>% mutate(
  Order = order(Departure)
)

# N4YBAA, N434AA
tn <- ontime %>% filter(TailNum=="N4YBAA") %>%  select(
  Departure, FlightDate, Order, Origin, Dest, Cancelled
)
tn <- tn[tn$Order,]
tn <- subset(tn, Cancelled == 0)

ghosts <- which(tn$Origin != lag(tn$Dest))
# for each ghost get two flights: 

tn[sort(c(ghosts, ghosts-1)),]

ghostFlight <- data.frame(
  TailNum=tn$TailNum[1], 
  Date = ymd(tn$FlightDate[ghosts]), 
  From=tn$Dest[ghosts-1], 
  To=tn$Origin[ghosts])
```