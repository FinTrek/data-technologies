---
knit: bookdown::preview_chapter
---

# US flights


HH: what I like to include here:

- discussion of airlines: number of passengers, centralized/de-centralization (hubs or not), fuel consumption
- discussion of delays: by time of day, day of week, airport, airline
- finding exceptions: delays of more than 24h, balloons at 600 mph, ...
- making a movie of the flights

I would also like to use new data rather than the Expo data.


There were 445,827 national flights recorded for January 2016:
```{r, message=FALSE, warning=FALSE}
library(ggplot2)
library(ggthemes)
ontime <- read.csv("data/airlines/ontime/On_Time_On_Time_Performance_2016_1.csv")
dim(ontime)
require(dplyr)
tails <- ontime %>% group_by(TailNum) %>% summarize(
  numFlights = n(),
  carrier = UniqueCarrier[1],
  miles = sum(Distance)
)
qplot(reorder(carrier, miles), miles, data=tails, varwidth=TRUE, fill=carrier, geom="boxplot") + ylim(c(0,150000)) 
qplot(miles, data=tails, fill=carrier) + xlim(c(0,150000)) + facet_wrap(~carrier, scales="free_y")
```
Southwest (WN) flies the heck out of its planes, but it is beaten at this game by a lot of the very small airline carriers, at the front of which is Spirit Airlines (NK).
What we cannot see from the boxplots is that some of these airline carriers have several modes for the number of miles that their planes fly. United and American seem to have a couple of planes that fly only very rarely. Carrier AS has two modes: one mode at a very high number of miles, the other at around 75,000 miles.  

All times in the ontime data set are in local time. This is problematic for almost any data analysis. Even ordering flights by their departure time over the course of a day is not possible unless we are only considering flights in the same time zone. 

Because all of the locations we are interested in, are airports, we can make use of the
[National Transportation Atlas Database](http://www.rita.dot.gov/bts/sites/rita.dot.gov.bts/files/publications/national_transportation_atlas_database/2011/index.html) provided by the Bureau of Transportation Statistics. In this database, airports are listed with geographic location in latitude and longitude. 
```{r, message=FALSE}
library(foreign)
airports <- read.dbf("data/airlines/airports/airports.dbf")
# we can reduce our data set to airports only 
table(airports$LAN_FA_TY)

airports <- subset(airports, LAN_FA_TY=="AIRPORT")
qplot(LONGITUDE, LATITUDE, data=airports)
```

There is a slew of different approaches and (semi-free) online services available to resolve issues around time zones. Here, we are using the Google Maps Time Zone API to get time zones for every one of the airports above. In order to run the following example, yu will have to sign up for this service to get an API key. Make yourself familiar with any limitations of the service so you don't accidentally ramp up any charges.

```{r, eval=FALSE}
timestamp <- 1452427200 # epoch time of Jan 10, 2016 12:00 pm

i <- 1
stringi <- sprintf("https://maps.googleapis.com/maps/api/timezone/json?location=%s,%s&timestamp=1452427200&key=PASTE-YOUR-KEY-HERE", airports$LATITUDE[i], airports$LONGITUDE[i])

library(rjson)
json_data <- fromJSON(file=stringi)
```

```{r, echo=FALSE, eval=FALSE}
timestamp <- 1452427200 # epoch time of Jan 10, 2016 12:00 pm
library(rjson)

#airport_tz <- NULL
for (i in 5644:5681) {
  stringi <- sprintf("https://maps.googleapis.com/maps/api/timezone/json?location=%s,%s&timestamp=1452427200&key=AIzaSyCYXzAUh7Tq9CQ9dHvNFdkZ7QBdrfKNS3U", airports$LATITUDE[i], airports$LONGITUDE[i])
  cat(i)
  cat("\n")
  json <- fromJSON(file=stringi)
  if (json$status =="OK") {
    temp <- data.frame(ID = airports$LOCID[i], json)
    airport_tz <- rbind(airport_tz, temp)
  } else {
    cat(json$status)
    cat("\n")
    if (json$status == "OVER_QUERY_LIMIT") return()
  }
}
write.csv(airport_tz, file="data/airport-timezones.csv", row.names=FALSE)
```

What kind of time shift does each of the time zones imply compared to a reference timezone and date? Using UTC as the reference time zone we calculate the difference in hours of the day on January 24 of 2016. 
```{r}
library(lubridate)
# reference date
pb.date <- ymd_hm("2016-01-24 12:00", tz="UTC")
hour(pb.date)
airport_tz <- read.csv("data/airport-timezones.csv")

airport_tz$timeZoneId <- as.character(airport_tz$timeZoneId)
airport_tz$tz_hours <- 12 - sapply(airport_tz$timeZoneId, function(x) hour(format(pb.date, tz=x, usetz=TRUE)))

airports <- merge(airports, airport_tz[, c("ID", "timeZoneName", "timeZoneId", "tz_hours")], all.x=TRUE, by.x="LOCID", by.y="ID")
qplot(data=airports, x=LONGITUDE, y = LATITUDE, colour=factor(tz_hours))
```

Using the time zone information we can transform local times at airports into global times referenced to UTC, which we then use to order the ontime data according to the time that flights took place ***needs a more precise definition***.
```{r}
# merge time zone data into ontime data by  origin and destination 
# adjust local departure times by origin and arrival times by destination

```
Order flights to identify ghost flights
```{r}
ontime$Departure <- lubridate::ymd(as.character(ontime$FlightDate))
hour(ontime$Departure) <- ontime$CRSDepTime %/% 100
minute(ontime$Departure) <- ontime$CRSDepTime %% 100  # this is where the timezones have to come in
```

This is how we get to ghost flights: for each individual plane (using tail number `TailNum` as an identifier), we weed out all flights that got cancelled (because presumably the plane won't move if its flight gets cancelled). We then sort flights according to their (scheduled) departure date and time. `LastDest` introduces a variable specifying the last destination a plane has flown into - if things go well, this should be the same as the origin from where the next flight is scheduled to take off. If `LastDest` and `Origin` are different airports, this indicates that at least one ghost flight has taken place, because the plane had to move somehow from its last destination to the new origin. 
```{r}
ghosts <- ontime %>% filter(TailNum != "") %>% 
  group_by(TailNum) %>% 
  select(
    Departure, FlightDate, Origin, Dest, Cancelled, UniqueCarrier
  ) %>% filter(Cancelled == 0) %>%  
  arrange(Departure) %>%
  mutate(
    LastDest = lag(Dest),
    Ghost = !(Origin == LastDest)
  ) %>% filter(Ghost)
dim(ghosts)
```
There are 9651 ghost flights in January 2016 (*** not adjusted by timezone - this might change a couple of flights ***).

HH: Caveat: if a plane is doing an international flight, it might create an 'artificial' ghost flight.
HH: what I would like to know: number of ghost miles flown. Fuel costs for ghost flights. 

```{r ghostrate, }
ghostsCarrier <- data.frame(xtabs(~UniqueCarrier, data=ghosts))
names(ghostsCarrier)[2] <- "Ghost"
flightsCarrier <- data.frame(xtabs(~UniqueCarrier, data=subset(ontime, Cancelled==0)))
names(flightsCarrier)[2] <- "Flight"

carrierStats <- merge(ghostsCarrier, flightsCarrier, by="UniqueCarrier")
qplot(Ghost/Flight * 1000, reorder(UniqueCarrier, Ghost/Flight), data=carrierStats, size=Flight) + ggtitle("Number of Ghosts for every 1000 Flights")
```

Figure \@ref(fig:ghostrate) shows the rate of ghost flights per each 1000 flights for each carrier. The size of the dots is proportional to the number of flights the airline carried out in January 2016, i.e. larger carriers are shown by larger sized dots. Generally, larger carriers have larger ghost rates, but there are some remarkable exceptions. Southwest (WN) has the lowest rate of ghost flights among the larger carriers, while Frontier Airlines (F9) has a very high ghost rate for such a small carrier.  

```{r ghostmap, fig.cap="Ghost flights of national airline carriers. Some hubs become apparent.", fig.height=4, fig.width=10, warning=FALSE}
ghosts <- merge(ghosts, airports[,c("LOCID", "LONGITUDE", "LATITUDE")], by.x="Origin", by.y="LOCID", all.x=TRUE)
names(ghosts)[grep("LONGITUDE", names(ghosts))] <- "orig.long"
names(ghosts)[grep("LATITUDE", names(ghosts))] <- "orig.lat"

ghosts <- merge(ghosts, airports[,c("LOCID", "LONGITUDE", "LATITUDE")], by.x="LastDest", by.y="LOCID", all.x=TRUE)
names(ghosts)[grep("LONGITUDE", names(ghosts))] <- "dest.long"
names(ghosts)[grep("LATITUDE", names(ghosts))] <- "dest.lat"

ghosts$LastDest <-as.character(ghosts$LastDest)
ghosts$Origin <-as.character(ghosts$Origin)
ghostPorts <- ghosts %>% split(.$UniqueCarrier) %>% purrr::map_df(
  function(x) {
    dframe <- data.frame(
      UniqueCarrier = x$UniqueCarrier[1], 
      ID = with(x, c(LastDest, Origin)))
    dframe %>% group_by(UniqueCarrier, ID) %>% summarize(
      ghosts = n())
  }
)
ghostPorts <- merge(ghostPorts, airports[,c("LOCID", "LONGITUDE", "LATITUDE")], by.x="ID", by.y="LOCID", all.x=TRUE)
ghostPorts <- ghostPorts %>% group_by(UniqueCarrier) %>% mutate(
  ghostPerc = ghosts / n() *100
)

states <- map_data("state")
ggplot() + theme_bw() + 
  geom_polygon(aes(long, lat, group=group), data=states, fill="grey80") +
  geom_segment(aes(x=orig.long, xend=dest.long, y=orig.lat, yend=dest.lat),
               data=subset(ghosts, UniqueCarrier %in% c("OO", "EV", "F9")),
               colour="darkorange", alpha=0.25) + facet_wrap(~UniqueCarrier) +
  xlim(c(-125, -60)) + ylim(c(25, 50)) + 
  theme_map() + 
  geom_label(
    aes(LONGITUDE, LATITUDE, label=ID), alpha=0.5,
    data=subset(ghostPorts, 
                UniqueCarrier %in% c("OO", "EV", "F9") & ghostPerc > 30))
```

